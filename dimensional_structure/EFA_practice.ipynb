{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.5/site-packages/IPython/parallel.py:13: ShimWarning: The `IPython.parallel` package has been deprecated since IPython 4.0. You should import from ipyparallel instead.\n",
      "  \"You should import from ipyparallel instead.\", ShimWarning)\n",
      "/usr/local/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "# imports\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from os import makedirs, path, remove\n",
    "import pickle\n",
    "import random\n",
    "from shutil import copyfile, copytree, rmtree\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "from dimensional_structure.results import Results\n",
    "from dimensional_structure.cross_results_plots import (plot_corr_heatmap, \n",
    "                                                       plot_glasso_edge_strength,\n",
    "                                                       plot_cross_within_prediction,\n",
    "                                                       plot_cross_relationship,\n",
    "                                                       plot_BIC,\n",
    "                                                       plot_cross_silhouette,\n",
    "                                                       plot_cross_communality)\n",
    "from dimensional_structure.cross_results_utils import run_cross_prediction\n",
    "from dimensional_structure.DA_plots import plot_DA\n",
    "from dimensional_structure.EFA_plots import plot_EFA\n",
    "from dimensional_structure.EFA_test_retest import (calc_EFA_retest,\n",
    "                                                   plot_EFA_change, \n",
    "                                                   plot_EFA_retest, \n",
    "                                                   plot_cross_EFA_retest)\n",
    "from dimensional_structure.HCA_plots import plot_HCA\n",
    "from dimensional_structure.prediction_plots import (plot_results_prediction,\n",
    "                                                    plot_prediction, \n",
    "                                                    plot_prediction_scatter,\n",
    "                                                    plot_prediction_comparison,\n",
    "                                                    plot_factor_fingerprint)\n",
    "from dimensional_structure.prediction_utils import run_group_prediction\n",
    "from selfregulation.utils.result_utils import load_results\n",
    "from selfregulation.utils.utils import get_info, get_recent_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "dataset=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset of interest\n",
    "basedir=get_info('base_directory')\n",
    "if dataset == None:\n",
    "    dataset = get_recent_dataset()\n",
    "dataset = path.join(basedir,'Data',dataset)\n",
    "datafile = dataset.split(path.sep)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Complete_02-22-2020'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label subsets\n",
    "demographic_factor_names = ['Drug Use',\n",
    "                            'Mental Health',\n",
    "                            'Problem Drinking',\n",
    "                            'Daily Smoking',\n",
    "                            'Binge Drinking',\n",
    "                            'Lifetime Smoking',\n",
    "                            'Obesity',\n",
    "                            'Income / Life Milestones']\n",
    "\n",
    "\n",
    "                                      \n",
    "subsets = [{'name': 'task', \n",
    "            'regex': 'task',\n",
    "            'oblimin_cluster_names': ['Conflict Processing',\n",
    "                                      'Information Processing',\n",
    "                                      'Shifting',\n",
    "                                      'Speeded Information Processing',\n",
    "                                      'Inhibition-Related Threshold',\n",
    "                                      'Caution',\n",
    "                                      'Perc/Resp',\n",
    "                                      'Inhibition-Related Perc/Resp',\n",
    "                                      'NA1',\n",
    "                                      'Discounting',\n",
    "                                      'NA2',\n",
    "                                      'Cold/Model-Based',\n",
    "                                      'Hot/Model-Free',\n",
    "                                      'NA3',\n",
    "                                      'NA4'],\n",
    "            'oblimin_factor_names': ['Speeded IP', 'Strategic IP', \n",
    "                                     'Perc / Resp','Caution', \n",
    "                                     'Discounting']\n",
    "                                     ,\n",
    "            'varimax_cluster_names': None,\n",
    "            'varimax_factor_names': ['Speeded IP', 'Strategic IP', \n",
    "                                     'Perc / Resp',  'Caution', \n",
    "                                     'Discounting'],\n",
    "            'predict': True},\n",
    "            {'name': 'survey',\n",
    "             'regex': 'survey',\n",
    "             'oblimin_cluster_names': ['Financial Risk-Taking',\n",
    "                                       'Eating',\n",
    "                                       'Behavioral Approach',\n",
    "                                       'Behavioral Inhibition',\n",
    "                                       'Mindfulness',\n",
    "                                       'Impulsivity',\n",
    "                                       'Goal-Direcedness',\n",
    "                                       'Ethical/Health Risk-Taking',\n",
    "                                       'Risk Perception',\n",
    "                                       'Sensation Seeking',\n",
    "                                       'Sociability',\n",
    "                                       'Reward Sensitivity'],\n",
    "             'oblimin_factor_names':  ['Sensation Seeking', 'Emotional Control',  \n",
    "                                   'Mindfulness', 'Impulsivity',\n",
    "                                   'Reward Sensitivity', 'Goal-Directedness', \n",
    "                                   'Risk Perception', 'Eating Control', \n",
    "                                   'Ethical Risk-Taking', 'Social Risk-Taking',\n",
    "                                   'Financial Risk-Taking', 'Agreeableness'],\n",
    "            'varimax_cluster_names': None,\n",
    "            'varimax_factor_names': None,\n",
    "             'predict': True},\n",
    "             {'name': 'main_subset', \n",
    "            'regex': 'main',\n",
    "            'oblimin_cluster_names': [],\n",
    "            'oblimin_factor_names': [],\n",
    "            'predict': False},\n",
    "             {'name': 'all', \n",
    "              'regex': '.',\n",
    "              'oblimin_cluster_names': [],\n",
    "              'oblimin_factor_names': [],\n",
    "              'predict': False}]\n",
    "\n",
    "selected_subsets = ['task', 'survey']\n",
    "\n",
    "bootstrap = True\n",
    "boot_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "SUBSET: TASK\n",
      "*******************************************************************************\n",
      "*******************************************************************************\n",
      "Analyzing Subset: task\n",
      "Getting dataset: /SRO/Data/Complete_02-22-2020...:\n",
      "file: meaningful_variables_imputed.csv \n",
      " \n",
      "Getting dataset: /SRO/Data/Complete_02-22-2020...:\n",
      "file: meaningful_variables_clean.csv \n",
      " \n",
      "*******************************************************************************\n",
      "Running demographics\n",
      "*******************************************************************************\n",
      "Is the data adequate for factor analysis? Yes\n",
      "Determining Optimal Dimensionality\n",
      "Best Components:  {'c_metric-BIC': 8}\n",
      "Creating Factor Tree\n",
      "No 8 factor solution computed yet! Computing...\n",
      "Determining Higher Order Factors\n",
      "# of components not specified, using BIC determined #\n",
      "*******************************************************************************\n",
      "Running EFA, rotate: oblimin\n",
      "*******************************************************************************\n",
      "Is the data adequate for factor analysis? Yes\n",
      "Determining Optimal Dimensionality\n",
      "Best Components:  {'c_metric-BIC': 8}\n",
      "Creating Factor Tree\n",
      "No 8 factor solution computed yet! Computing...\n",
      "Determining Higher Order Factors\n",
      "# of components not specified, using BIC determined #\n",
      "*******************************************************************************\n",
      "Running HCA\n",
      "*******************************************************************************\n",
      "Clustering data\n",
      "Clustering EFA\n",
      "No 5 factor solution computed yet! Computing...\n",
      "*******************************************************************************\n",
      "Running EFA, rotate: varimax\n",
      "*******************************************************************************\n",
      "Creating Factor Tree\n",
      "No 8 factor solution computed yet! Computing...\n",
      "Determining Higher Order Factors\n",
      "# of components not specified, using BIC determined #\n",
      "*******************************************************************************\n",
      "Running HCA\n",
      "*******************************************************************************\n",
      "Clustering data\n",
      "Clustering EFA\n",
      "No 5 factor solution computed yet! Computing...\n",
      "Saving Subset: task\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "all_results = None\n",
    "ID = str(random.getrandbits(16)) \n",
    "# create/run results for each subset\n",
    "for subset in [subsets[0]]: ##CHANGE ONCE YOU CAN GET THIS IN A STRAIGHT RUN THROUGH\n",
    "    name = subset['name']\n",
    "    if verbose:\n",
    "        print('*'*79)\n",
    "        print('SUBSET: %s' % name.upper())\n",
    "        print('*'*79)\n",
    "    if selected_subsets is not None and name not in selected_subsets:\n",
    "        continue\n",
    "\n",
    "    print('*'*79)\n",
    "    print('Analyzing Subset: %s' % name)\n",
    "    # ****************************************************************************\n",
    "    # Laad Data\n",
    "    # ****************************************************************************\n",
    "    # run dimensional analysis\n",
    "    start = time.time()\n",
    "    results = Results(datafile=datafile, \n",
    "                      dist_metric='abscorrelation',\n",
    "                      name=subset['name'],\n",
    "                      filter_regex=subset['regex'],\n",
    "                      boot_iter=boot_iter,\n",
    "                      ID=ID,\n",
    "                      residualize_vars=['Age', 'Sex'])\n",
    "    results.run_demographic_analysis(verbose=verbose, bootstrap=bootstrap)\n",
    "    for rotate in ['oblimin', 'varimax']:\n",
    "        results.run_EFA_analysis(rotate=rotate, \n",
    "                                 verbose=verbose, \n",
    "                                 bootstrap=bootstrap)\n",
    "        results.run_clustering_analysis(rotate=rotate, \n",
    "                                        verbose=verbose, \n",
    "                                        run_graphs=False)\n",
    "        c = results.EFA.get_c()\n",
    "        # name factors and clusters\n",
    "        factor_names = subset.get('%s_factor_names' % rotate, None)\n",
    "        cluster_names = subset.get('%s_cluster_names' % rotate, None)\n",
    "        if factor_names:\n",
    "            results.EFA.name_factors(factor_names, rotate=rotate)\n",
    "        if cluster_names:\n",
    "            results.HCA.name_clusters(cluster_names, inp='EFA%s_%s' % (c, rotate))\n",
    "    ID = results.ID.split('_')[1]\n",
    "    results.DA.name_factors(demographic_factor_names)\n",
    "    if verbose: print('Saving Subset: %s' % name)\n",
    "    id_file = results.save_results()\n",
    "    # ***************************** saving ****************************************\n",
    "    # copy latest results and prediction to higher directory\n",
    "    copyfile(id_file, path.join(path.dirname(results.get_output_dir()), \n",
    "                                '%s_results.pkl' % name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('cluster0', 0    0.035808\n",
       "              1    0.035140\n",
       "              2    0.038311\n",
       "              3    0.022224\n",
       "              4    0.032278\n",
       "              5    0.019283\n",
       "              6    0.637637\n",
       "              7    0.143033\n",
       "              dtype: float64), ('cluster1', 0    0.020307\n",
       "              1    0.045307\n",
       "              2    0.055493\n",
       "              3    0.754076\n",
       "              4    0.041883\n",
       "              5    0.026116\n",
       "              6    0.028908\n",
       "              7    0.019630\n",
       "              dtype: float64), ('cluster2', 0    0.043987\n",
       "              1    0.188524\n",
       "              2    0.104175\n",
       "              3    0.018932\n",
       "              4    0.064326\n",
       "              5    0.585827\n",
       "              6    0.028443\n",
       "              7    0.022844\n",
       "              dtype: float64), ('cluster3', 0    0.053541\n",
       "              1    0.136329\n",
       "              2    0.080923\n",
       "              3    0.047624\n",
       "              4    0.043498\n",
       "              5    0.282215\n",
       "              6    0.030133\n",
       "              7    0.011614\n",
       "              dtype: float64), ('cluster4', 0    0.078552\n",
       "              1    0.030703\n",
       "              2    0.032470\n",
       "              3    0.018812\n",
       "              4    0.049250\n",
       "              5    0.040308\n",
       "              6    0.046365\n",
       "              7    0.539009\n",
       "              dtype: float64), ('cluster5', 0    0.185896\n",
       "              1    0.139278\n",
       "              2    0.230962\n",
       "              3    0.026680\n",
       "              4    0.070334\n",
       "              5    0.068008\n",
       "              6    0.102115\n",
       "              7    0.041446\n",
       "              dtype: float64), ('cluster6', 0    0.088446\n",
       "              1    0.088309\n",
       "              2    0.149824\n",
       "              3    0.046970\n",
       "              4    0.196382\n",
       "              5    0.041854\n",
       "              6    0.033133\n",
       "              7    0.056718\n",
       "              dtype: float64), ('cluster7', 0    0.045638\n",
       "              1    0.038483\n",
       "              2    0.170824\n",
       "              3    0.015946\n",
       "              4    0.158733\n",
       "              5    0.041330\n",
       "              6    0.032557\n",
       "              7    0.071602\n",
       "              dtype: float64), ('cluster8', 0    0.107169\n",
       "              1    0.223850\n",
       "              2    0.146805\n",
       "              3    0.051161\n",
       "              4    0.267058\n",
       "              5    0.037239\n",
       "              6    0.027123\n",
       "              7    0.034981\n",
       "              dtype: float64), ('cluster9', 0    0.083623\n",
       "              1    0.079092\n",
       "              2    0.083156\n",
       "              3    0.023721\n",
       "              4    0.384665\n",
       "              5    0.047940\n",
       "              6    0.040184\n",
       "              7    0.046396\n",
       "              dtype: float64), ('cluster10', 0    0.080588\n",
       "              1    0.516334\n",
       "              2    0.116579\n",
       "              3    0.061533\n",
       "              4    0.146061\n",
       "              5    0.027720\n",
       "              6    0.060093\n",
       "              7    0.032125\n",
       "              dtype: float64), ('cluster11', 0    0.175323\n",
       "              1    0.149819\n",
       "              2    0.167755\n",
       "              3    0.021878\n",
       "              4    0.055090\n",
       "              5    0.076945\n",
       "              6    0.034799\n",
       "              7    0.031536\n",
       "              dtype: float64), ('cluster12', 0    0.075728\n",
       "              1    0.384453\n",
       "              2    0.187285\n",
       "              3    0.043703\n",
       "              4    0.128592\n",
       "              5    0.071383\n",
       "              6    0.108112\n",
       "              7    0.046629\n",
       "              dtype: float64), ('cluster13', 0    0.268346\n",
       "              1    0.071641\n",
       "              2    0.118094\n",
       "              3    0.046429\n",
       "              4    0.138597\n",
       "              5    0.047941\n",
       "              6    0.086542\n",
       "              7    0.027083\n",
       "              dtype: float64), ('cluster14', 0    0.395408\n",
       "              1    0.066023\n",
       "              2    0.063921\n",
       "              3    0.057737\n",
       "              4    0.067817\n",
       "              5    0.032791\n",
       "              6    0.052579\n",
       "              7    0.045151\n",
       "              dtype: float64), ('cluster15', 0    0.080773\n",
       "              1    0.084953\n",
       "              2    0.058725\n",
       "              3    0.059633\n",
       "              4    0.021631\n",
       "              5    0.016840\n",
       "              6    0.035232\n",
       "              7    0.017447\n",
       "              dtype: float64), ('cluster16', 0    0.293919\n",
       "              1    0.058531\n",
       "              2    0.150927\n",
       "              3    0.033524\n",
       "              4    0.078166\n",
       "              5    0.038610\n",
       "              6    0.033832\n",
       "              7    0.067762\n",
       "              dtype: float64), ('cluster17', 0    0.114770\n",
       "              1    0.071668\n",
       "              2    0.343564\n",
       "              3    0.055298\n",
       "              4    0.063552\n",
       "              5    0.045397\n",
       "              6    0.074002\n",
       "              7    0.041347\n",
       "              dtype: float64)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.HCA.get_cluster_loading(results.EFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_plot=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "Plotting Subset: task\n",
      "** Plotting DA **\n",
      "Plotting Distributions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/matplotlib/font_manager.py:1316: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting factor correlations\n",
      "Plotting factor bars\n",
      "** Plotting EFA oblimin **\n",
      "Plotting communality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/scipy/stats/stats.py:1633: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting factor bars\n",
      "Plotting factor heatmap\n",
      "Plotting factor correlations\n",
      "using correct transfer_scores\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "transform_remove_skew() got an unexpected keyword argument 'drop_failed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-80b7f265481f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Plot EFA retest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mcombined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mthe_rest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_EFA_retest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         plot_EFA_retest(combined=combined, \n\u001b[1;32m     45\u001b[0m                         \u001b[0mplot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEFA_plot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/SRO/dimensional_structure/dimensional_structure/EFA_test_retest.py\u001b[0m in \u001b[0;36mcalc_EFA_retest\u001b[0;34m(results, rotate, verbose)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mshared_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretest_data_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mretest_data_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretest_data_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshared_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mretest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransfer_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretest_data_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mretest_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' Retest'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mretest_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# scale and perform the factor score transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/SRO/dimensional_structure/dimensional_structure/utils.py\u001b[0m in \u001b[0;36mtransfer_scores\u001b[0;34m(data, results, rotate)\u001b[0m\n\u001b[1;32m    466\u001b[0m                                  \u001b[0mpositive_skewed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositive_skewed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                                  \u001b[0mnegative_skewed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative_skewed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                                  drop_failed=False)\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_outliers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0mdata_imputed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: transform_remove_skew() got an unexpected keyword argument 'drop_failed'"
     ]
    }
   ],
   "source": [
    "    # ****************************************************************************\n",
    "    # Plotting\n",
    "    # ****************************************************************************\n",
    "    dpi = 300\n",
    "    ext = 'png'\n",
    "    size = 4.6\n",
    "    if run_plot==True:\n",
    "        if verbose:\n",
    "            print('*'*79)\n",
    "            print('Plotting Subset: %s' % name)\n",
    "        if results is None or name not in results.ID:\n",
    "            results = load_results(datafile, name=name)[name]\n",
    "        plot_dir = results.get_plot_dir()\n",
    "        DA_plot_dir = path.join(plot_dir, 'DA')\n",
    "        EFA_plot_dir = path.join(plot_dir, 'EFA')\n",
    "        HCA_plot_dir = path.join(plot_dir, 'HCA')\n",
    "        prediction_plot_dir = path.join(plot_dir, 'prediction')\n",
    "        makedirs(DA_plot_dir, exist_ok = True)\n",
    "        makedirs(EFA_plot_dir, exist_ok = True)\n",
    "        makedirs(HCA_plot_dir, exist_ok = True)\n",
    "        \n",
    "        # set up kws for plotting functions\n",
    "        tasks = np.unique([i.split('.')[0] for i in results.data.columns])\n",
    "        if name == 'task':\n",
    "            plot_task_kws= {'task_sublists': {'tasks': [t for t in tasks if 'survey' not in t]}}\n",
    "        elif name == 'survey':\n",
    "            plot_task_kws= {'task_sublists': {'surveys': [t for t in tasks if 'survey' in t]}}\n",
    "        else:\n",
    "            plot_task_kws={}\n",
    "         \n",
    "            # Plot EFA\n",
    "        if verbose: print(\"** Plotting DA **\")\n",
    "        plot_DA(results, DA_plot_dir, verbose=verbose, size=size, dpi=dpi, ext=ext)\n",
    "        \n",
    "        for rotate in ['oblimin', 'varimax']:\n",
    "            # Plot EFA\n",
    "            if verbose: print(\"** Plotting EFA %s **\" % rotate)\n",
    "            plot_EFA(results, EFA_plot_dir, rotate=rotate,\n",
    "                     verbose=verbose, size=size, dpi=dpi, \n",
    "                     ext=ext, plot_task_kws=plot_task_kws)\n",
    "            \n",
    "            # Plot EFA retest\n",
    "            combined, *the_rest = calc_EFA_retest(results, rotate=rotate)\n",
    "            plot_EFA_retest(combined=combined, \n",
    "                            plot_dir=path.join(EFA_plot_dir, rotate), \n",
    "                            size=size, dpi=dpi, ext=ext)\n",
    "            plot_EFA_change(combined=combined, \n",
    "                            plot_dir=path.join(EFA_plot_dir, rotate),\n",
    "                            size=size, dpi=dpi, ext=ext)\n",
    "            # Plot HCA\n",
    "            if verbose: print(\"** Plotting HCA %s **\" % rotate)\n",
    "            drop_list = {('task', 'oblimin'): ([1,5,8,9,12,15],[2,4,6,14]) ,\n",
    "                         ('survey', 'oblimin'): ([0,2,4,6,8,10], None)}\n",
    "            drop1, drop2 = drop_list.get((name, rotate), (None, None))\n",
    "            plot_HCA(results, HCA_plot_dir, rotate=rotate,\n",
    "                     drop_list = drop1, double_drop_list=drop2,\n",
    "                     size=size, dpi=dpi, ext='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
